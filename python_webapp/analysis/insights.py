"""
ìë™ Insight ìƒì„± (3-way ë¹„êµ + í†µê³„)

ê³¼í•™ì  ì‹¤í—˜ ì›ì¹™:
  - ë°˜ë³µ ì¸¡ì • (10íšŒ) â†’ í‰ê· /í‘œì¤€í¸ì°¨
  - í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ (t-test)
  - ë©”íŠ¸ë¦­ ì •ì˜ ëª…í™•í™”
"""
from typing import List, Dict
import numpy as np
from scipy import stats
from scheduler.thread import Thread
from scheduler.cfs import CFSScheduler


def calculate_jains_index(values: List[float]) -> float:
    """
    Jain's Fairness Index

    ì •ì˜: J = (Î£x_i)^2 / (n * Î£x_i^2)
    where x_i = ië²ˆì§¸ ìŠ¤ë ˆë“œì˜ ì¸¡ì •ê°’ (CPU time, throughput ë“±)

    í•´ì„:
      - 1.0: ì™„ì „ ê³µì • (ëª¨ë‘ ë™ì¼)
      - 0.0: ì™„ì „ ë¶ˆê³µì • (í•œìª½ë§Œ ë…ì )
      - >0.95: ìš°ìˆ˜í•œ ê³µì •ì„±
    """
    if not values:
        return 0.0
    n = len(values)
    sum_x = sum(values)
    sum_x2 = sum(x*x for x in values)
    return (sum_x ** 2) / (n * sum_x2) if sum_x2 > 0 else 0.0


def calculate_statistics(values: List[float]) -> Dict:
    """
    í†µê³„ëŸ‰ ê³„ì‚° (ë°˜ë³µ ì¸¡ì •ìš©)

    Returns:
        mean: í‰ê· 
        std: í‘œì¤€í¸ì°¨
        min: ìµœì†Œê°’
        max: ìµœëŒ€ê°’
        ci_lower: 95% ì‹ ë¢°êµ¬ê°„ í•˜í•œ
        ci_upper: 95% ì‹ ë¢°êµ¬ê°„ ìƒí•œ
    """
    if not values:
        return {}

    mean = np.mean(values)
    std = np.std(values, ddof=1)  # í‘œë³¸ í‘œì¤€í¸ì°¨
    n = len(values)

    # 95% ì‹ ë¢°êµ¬ê°„ ê³„ì‚° (t-distribution)
    ci = stats.t.interval(0.95, n-1, loc=mean, scale=std/np.sqrt(n))

    return {
        'mean': mean,
        'std': std,
        'min': np.min(values),
        'max': np.max(values),
        'ci_lower': ci[0],
        'ci_upper': ci[1]
    }


def test_statistical_significance(values_a: List[float], values_b: List[float]) -> Dict:
    """
    í†µê³„ì  ìœ ì˜ì„± ê²€ì¦ (t-test)

    Returns:
        t_statistic: t í†µê³„ëŸ‰
        p_value: p-value
        significant: ìœ ì˜ë¯¸í•œê°€? (p < 0.05)
        effect_size: Cohen's d (íš¨ê³¼ í¬ê¸°)
    """
    if len(values_a) < 2 or len(values_b) < 2:
        return {}

    # ë…ë¦½ í‘œë³¸ t-ê²€ì •
    t_stat, p_value = stats.ttest_ind(values_a, values_b)

    # Cohen's d (íš¨ê³¼ í¬ê¸°)
    pooled_std = np.sqrt((np.std(values_a, ddof=1)**2 + np.std(values_b, ddof=1)**2) / 2)
    cohens_d = (np.mean(values_a) - np.mean(values_b)) / pooled_std if pooled_std > 0 else 0

    return {
        't_statistic': t_stat,
        'p_value': p_value,
        'significant': p_value < 0.05,
        'effect_size': cohens_d
    }


def calculate_scheduler_metrics(threads: List[Thread]) -> Dict:
    """ìŠ¤ì¼€ì¤„ëŸ¬ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    if not threads:
        return {}

    # í‰ê·  ëŒ€ê¸° ì‹œê°„
    avg_wait = sum(t.wait_time for t in threads) / len(threads)

    # ì™„ë£Œëœ ìŠ¤ë ˆë“œë“¤ì˜ ë°˜í™˜ ì‹œê°„
    completed = [t for t in threads if t.finish_time >= 0]
    avg_turnaround = (
        sum(t.finish_time - t.arrival_time for t in completed) / len(completed)
        if completed else None
    )

    # ê³µì •ì„± ì§€ìˆ˜ (runnable ì‹œê°„ ëŒ€ë¹„ ê°€ì¤‘ì¹˜ ë¹„ìœ¨ ê¸°ë°˜)
    wait_times = [t.wait_time for t in threads]
    cpu_times = []
    entitlements = []
    for t in threads:
        if t.burst_time <= 0:
            continue
        cpu_used = max(0, t.burst_time - t.remaining_time)
        runnable_time = getattr(t, "runnable_time", 0)
        if runnable_time <= 0:
            continue
        cpu_times.append(cpu_used)
        # CFS weight í…Œì´ë¸”ì„ ê³µí†µ entitlementë¡œ ì‚¬ìš© (nice ê¸°ë°˜ ê°€ì¤‘ì¹˜)
        weight = getattr(t, "weight", None)
        if weight is None or weight <= 0:
            weight = CFSScheduler.get_weight(t.nice)
        entitlements.append(runnable_time * weight)

    if cpu_times and entitlements:
        total_cpu = sum(cpu_times)
        total_weight = sum(entitlements)
        if total_cpu > 0 and total_weight > 0:
            # ì‹¤ì¸¡ ë¹„ì¤‘ / ê¸°ëŒ€ ë¹„ì¤‘ì´ ëª¨ë‘ ë™ì¼í•˜ë©´ ì™„ì „ ê³µì •(=1.0)
            share_ratios = [
                (cpu / total_cpu) / (weight / total_weight)
                for cpu, weight in zip(cpu_times, entitlements)
                if weight > 0
            ]
            fairness = calculate_jains_index(share_ratios) if share_ratios else 0.0
        else:
            fairness = 0.0
    else:
        fairness = 0.0
    fairness = round(fairness, 4)

    # Starvation ê°ì§€
    # - ê³µì •ì„± ì§€ìˆ˜ê°€ ë†’ìœ¼ë©´ (â‰¥0.85) starvation ì—†ìŒ
    # - í‰ê·  ëŒ€ê¸° ì‹œê°„ì˜ 15ë°° ì´ìƒì¸ ìŠ¤ë ˆë“œê°€ ìˆëŠ” ê²½ìš°
    has_starvation = False
    if fairness < 0.85 and avg_wait > 0:
        max_wait = max(wait_times) if wait_times else 0
        has_starvation = (max_wait > avg_wait * 15)

    # CPU time ratio (nice íš¨ê³¼ ì¸¡ì •)
    # Niceê°€ ë‹¤ë¥¸ ê·¸ë£¹ ê°„ CPU ì‹œê°„ ë¹„ìœ¨ ê³„ì‚°
    cpu_time_ratio = None
    nice_values = set(t.nice for t in threads)
    if len(nice_values) >= 2:
        # Nice ê°’ìœ¼ë¡œ ê·¸ë£¹í™”
        nice_groups = {}
        for t in threads:
            if t.nice not in nice_groups:
                nice_groups[t.nice] = []
            # CPU time = burst_time - remaining_time
            cpu_time = t.burst_time - t.remaining_time
            nice_groups[t.nice].append(cpu_time)

        # ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„(ê°€ì¥ ë‚®ì€ nice)ì™€ ê°€ì¥ ë‚®ì€ ìš°ì„ ìˆœìœ„(ê°€ì¥ ë†’ì€ nice) ë¹„êµ
        sorted_nices = sorted(nice_groups.keys())
        high_priority_nice = sorted_nices[0]  # ê°€ì¥ ë‚®ì€ nice (ë†’ì€ ìš°ì„ ìˆœìœ„)
        low_priority_nice = sorted_nices[-1]  # ê°€ì¥ ë†’ì€ nice (ë‚®ì€ ìš°ì„ ìˆœìœ„)

        high_priority_cpu = sum(nice_groups[high_priority_nice])
        low_priority_cpu = sum(nice_groups[low_priority_nice])

        if low_priority_cpu > 0:
            cpu_time_ratio = high_priority_cpu / low_priority_cpu
        elif high_priority_cpu > 0:
            # ë‚®ì€ ìš°ì„ ìˆœìœ„ê°€ í•œ ë²ˆë„ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê²½ìš°: ê³¼ë„í•œ ë¹„ìœ¨ ëŒ€ì‹  ì‚¬ìš©ëœ CPU ì‹œê°„ìœ¼ë¡œ ëŒ€ì²´
            cpu_time_ratio = float(high_priority_cpu)
        else:
            cpu_time_ratio = 1.0

    # ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹˜ ìˆ˜ (ìŠ¤ì¼€ì¼ í…ŒìŠ¤íŠ¸ìš©)
    context_switches = threads[0].context_switches if hasattr(threads[0], "context_switches") else 0

    return {
        'avg_wait': avg_wait,
        'avg_turnaround': avg_turnaround,
        'fairness': fairness,
        'has_starvation': has_starvation,
        'cpu_time_ratio': cpu_time_ratio,
        'context_switches': context_switches
    }


def generate_3way_comparison_report(
    basic_threads: List[Thread],
    mlfqs_threads: List[Thread],
    cfs_threads: List[Thread]
) -> Dict:
    """3-way ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
    results = {
        'basic': basic_threads,
        'mlfqs': mlfqs_threads,
        'cfs': cfs_threads
    }
    return generate_comparison_report(results, primary_metric='avg_wait')


def generate_comparison_report(
    scheduler_results: Dict[str, List[Thread]],
    primary_metric: str = 'avg_wait'
) -> Dict:
    """
    ìœ ì—°í•œ ìŠ¤ì¼€ì¤„ëŸ¬ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        scheduler_results: {'scheduler_name': [threads]} í˜•íƒœ
        primary_metric: ì£¼ìš” ë¹„êµ ë©”íŠ¸ë¦­

    Returns:
        ë¹„êµ ë¦¬í¬íŠ¸ ë”•ì…”ë„ˆë¦¬
    """
    # ê° ìŠ¤ì¼€ì¤„ëŸ¬ ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = {}
    for scheduler_name, threads in scheduler_results.items():
        metrics[scheduler_name] = calculate_scheduler_metrics(threads)

    # Baseline ê²°ì • (basicì´ ìˆìœ¼ë©´ baseline, ì—†ìœ¼ë©´ ì²«ë²ˆì§¸)
    scheduler_names = list(scheduler_results.keys())
    baseline_name = 'basic' if 'basic' in scheduler_names else scheduler_names[0]
    baseline_metrics = metrics[baseline_name]
    baseline_value = baseline_metrics.get(primary_metric, 0)

    # ê°œì„ ìœ¨ ê³„ì‚°
    improvements = {}
    for name, sched_metrics in metrics.items():
        if name == baseline_name:
            continue

        current_value = sched_metrics.get(primary_metric, 0)
        if current_value is None or baseline_value is None:
            continue

        # ë©”íŠ¸ë¦­ ì¢…ë¥˜ì— ë”°ë¼ ê°œì„  ë°©í–¥ ê²°ì •
        if primary_metric in ['avg_wait', 'avg_turnaround', 'context_switches']:
            # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
            if baseline_value > 1.0:
                improvement = ((baseline_value - current_value) / baseline_value * 100)
            else:
                improvement = baseline_value - current_value
        elif primary_metric in ['fairness', 'cpu_time_ratio']:
            # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            if baseline_value > 0.01:
                improvement = ((current_value - baseline_value) / baseline_value * 100)
            else:
                improvement = current_value - baseline_value
        else:
            improvement = 0

        improvements[f"{name}_vs_{baseline_name}"] = improvement

    # ìŠ¹ì ê²°ì • (primary_metric ê¸°ì¤€)
    if primary_metric in ['avg_wait', 'avg_turnaround', 'context_switches']:
        # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        winner = min(metrics.items(), key=lambda x: x[1].get(primary_metric, float('inf')))[0]
    elif primary_metric in ['fairness', 'cpu_time_ratio']:
        # ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
        winner = max(metrics.items(), key=lambda x: x[1].get(primary_metric, 0))[0]
    else:
        winner = list(metrics.keys())[0]

    # Insight ìƒì„±
    insights = generate_insights(metrics, scheduler_names, primary_metric, improvements, baseline_name)

    return {
        'winner': winner,
        'metrics': metrics,
        'improvements': improvements,
        'insights': insights,
        'baseline': baseline_name,
        'primary_metric': primary_metric
    }


def generate_insights(
    metrics: Dict[str, Dict],
    scheduler_names: List[str],
    primary_metric: str,
    improvements: Dict[str, float],
    baseline_name: str
) -> List[str]:
    """Insight ìƒì„±"""
    insights = []

    # 1. ê°œì„  íš¨ê³¼ (ê°œì„ ìœ¨ì´ 10% ì´ìƒì¸ ê²½ìš°)
    significant_improvements = {k: v for k, v in improvements.items() if abs(v) > 10}
    if significant_improvements:
        improvement_strs = [f"{k.split('_vs_')[0].upper()} {v:+.1f}%"
                           for k, v in significant_improvements.items()]
        insights.append(
            f"ğŸ’¡ ê°œì„  íš¨ê³¼ (vs {baseline_name.upper()}): " + ", ".join(improvement_strs)
        )

    # 2. ê³µì •ì„± ë¹„êµ (fairnessê°€ ìˆëŠ” ê²½ìš°)
    if any('fairness' in m for m in metrics.values()):
        fairness_scores = {name: m.get('fairness', 0) for name, m in metrics.items()}
        best_fairness = max(fairness_scores.items(), key=lambda x: x[1])
        if best_fairness[1] > 0.9:
            insights.append(
                f"âš–ï¸ ê³µì •ì„±: {best_fairness[0].upper()}ê°€ ê°€ì¥ ìš°ìˆ˜ "
                f"(Jain Index: {best_fairness[1]:.4f})"
            )

    # 3. Starvation ê²½ê³  (basicì´ í¬í•¨ëœ ê²½ìš°)
    if 'basic' in metrics:
        if metrics['basic'].get('has_starvation', False):
            other_schedulers = [s for s in scheduler_names if s != 'basic']
            if other_schedulers:
                insights.append(
                    f"âš ï¸ Basic PriorityëŠ” Starvation ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤. "
                    f"{', '.join(s.upper() for s in other_schedulers)}ëŠ” ì•ˆì „í•©ë‹ˆë‹¤."
                )

    # 4. ë©”íŠ¸ë¦­ë³„ ê¶Œì¥ì‚¬í•­
    if primary_metric == 'avg_wait':
        insights.append(
            "ğŸ“ˆ ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”:\n"
            "  - Interactive ì‘ì—…ì— ì í•©\n"
            "  - ì‚¬ìš©ì ì‘ë‹µì„±ì´ ì¤‘ìš”í•œ ê²½ìš°"
        )
    elif primary_metric == 'avg_turnaround':
        insights.append(
            "ğŸ“ˆ ë°˜í™˜ ì‹œê°„ ìµœì†Œí™”:\n"
            "  - ë°°ì¹˜ ì‘ì—… ì²˜ë¦¬ì— ì í•©\n"
            "  - ì „ì²´ ì²˜ë¦¬ëŸ‰ì´ ì¤‘ìš”í•œ ê²½ìš°"
        )
    elif primary_metric == 'fairness':
        insights.append(
            "ğŸ“ˆ ê³µì •ì„± ìµœëŒ€í™”:\n"
            "  - ëª¨ë“  ì‘ì—…ì— ê³µí‰í•œ ê¸°íšŒ\n"
            "  - Starvation ë°©ì§€"
        )
    elif primary_metric == 'cpu_time_ratio':
        insights.append(
            "ğŸ“ˆ CPU ì‹œê°„ ë¹„ìœ¨ í–¥ìƒ:\n"
            "  - ë‚®ì€ nice(ë†’ì€ ìš°ì„ ìˆœìœ„) ê·¸ë£¹ì´ ì–¼ë§ˆë‚˜ ë” ë§ì€ CPUë¥¼ ê°€ì ¸ê°”ëŠ”ì§€ ì¸¡ì •\n"
            "  - ê°’ì´ ë†’ì„ìˆ˜ë¡ nice ì°¨ì´ë¥¼ ì œëŒ€ë¡œ ë°˜ì˜"
        )

    return insights
